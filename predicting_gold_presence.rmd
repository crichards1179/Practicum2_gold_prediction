---
title: "Regis University, Master of Science in Data Science, Practicum II - Predicting Gold Presence"
author: "Matt Twigg"
date: "8/22/2020"
output: html_document
---

```{r setup, message=FALSE , warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction  

I used to live in the Black Hills and would go gold panning. Unfortunately, I never found any gold even though I had heard that only half of the gold in the Black Hills had been extracted. Also, gold panning can be tiring as one sits or stands in the same position for a while.  It occurs to me that if I use data science techniques, I might be able to predict where to find gold. If gold shows up with certain other minerals, I can narrow down the areas that I pan for gold. I will create a train/test split to test for accuracy and use support vector machine for classification and prediction of gold.

My specific research question is “Can the presence of gold be predicted from the presence of other minerals?” 

## Methods 

The USGS is a great resource for understanding where minerals were found and what minerals were present. I plan to use data sets from https://mrdata.usgs.gov/mrds/geo-inventory.php for Lawrence County, South Dakota to predict whether gold can be found in the area of other minerals. These data sets give latitude, longitude, and mineral data for given locations. The data sets have missing values, characters, and multiple pieces of information in single fields. The data will have to be cleaned and prepped in order to be useful. Multiple data sets will have to be combined into one data frame. Multiple rows will have to be dropped and only some fields selected. I will be using Rstudio to work with the data sets and storing the rmarkdown on GitHub. 

I am starting off with the following null and alternative hypothesis for the independent variables gold, silver, and lead (I looked at the two most prevalent minerals after gold. In order for the presence of silver or lead to predict the presence of gold, difference between the groups can not be due to chance.

Null hypthesis: any differences in the groups are due to chance - they are not significant. 
Alternative hypothesis: differences are not due to chance - they are significant
 

### Libraries used
```{r message=FALSE ,warning=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(corrplot)
library(factoextra)
library(e1071)
library(caret)
library(class)
library(gmodels)
```

## Exploration  
Data read in from https://mrdata.usgs.gov/mrds/geo-inventory.php for Lawrence County, South Dakota.
```{r message=FALSE ,warning=FALSE}
dn <- read.csv("deadwoodnorth.csv")
ds <- read.csv("deadwoodsouth.csv")
ld <- read.csv("lead.csv")
tn <- read_csv("tinton.csv")
sp <- read_csv("spearfish.csv")
```
Here I bind all the data frames into one data frame.  
```{r}
sites <- rbind(dn, ds, ld, tn, sp)
```
I select only the fields that I will need from the sites data frame.
```{r}
s1 <- sites %>% select(
  dep_id,
  site_name,
  latitude,
  longitude,
  commod1,
  commod2,
  commod3,
)
```
I copy the data frame to s2.
```{r}
s2 <- data.frame(s1)
```
I have to change one of the columns to factor to make it match the other two commod columns.
```{r}
s2$commod2 <- as.factor(s2$commod2)
```
Here is the structure of the new data frame.
```{r}
str(s2)
```
I unite commod1, 2, and 3 into one column called commodities.
```{r}
s2com <- unite(s2, commodities, 5:7, sep = ", ")
#str(s2com)
```
I create a vector with TRUE or FALSE for the presence of gold in each row of the data frame.
```{r}
au <- str_detect(s2com$commodities, "Gold")
```
I add that column to the data frame.
```{r}
s2com1 <- cbind(s2com, au)
```
I reassemble the data frame with all gold mining in the first 299 rows of the data frame.
```{r}
reds2com <- subset(s2com1, au == TRUE)
reds2comF <- subset(s2com1, au == FALSE)
reds <- rbind(reds2com, reds2comF)
```
I give the rows numbers for easy reference.  
```{r}
rownames(reds) <- 1:nrow(reds)
```
I separate out each mineral into its own column.
```{r}
colreds <- reds %>% separate(commodities, c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", "seventeen", "eighteen"), "," ) 
```
I need to know which columns are empty so I count the NA values. 
```{r}
colSums(is.na(colreds))
```
and any columns that have 403 NAs get cut.  
```{r}
reducedcol <- colreds %>% select(1:15)
```
I replace NA with no spaces, create a new data frame, make sure there are no more NA values, and unite all the expanded columns into one commodities column for easy reading of minerals. I then write the file out to be worked on manually, the final step in turning categorical data into quantitative discrete data.
```{r}
noNA <- reducedcol %>% replace_na(list(four = "", five = "", six  = "", seven  = "", eight  = "", nine = "", ten  = "", eleven  = ""))
noNA[noNA == " NA"] <- ""
outFull <- unite(noNA, commodities, 5:15, sep = ", ")
#write.csv(outFull, file = "outFull2.csv")
```
Here I read in the new data set with each mineral having its own column.
```{r}
imported <- read.csv("inFull2.csv")
```
I need to see the structure of the new data set. Here I see that the mineral variables are numerical and discrete.
```{r}
str(imported)
```
I also want to write out the lat/long data for gold mines. I will use this later in Google Maps.
```{r}
allLatLong <- imported[3:5]
latLong <- allLatLong[1:299,]
write.csv(latLong, file = "latLong.csv")
```


```{r}
#added <- colSums(imported[7:38])
#class(added)
```






## Visualizations  

I want to see  the sums of each mineral. Here is the count visualized. It looks like Gold, Silver, and Lead had the most observations
```{r}

colMinerals <- names(imported)
added <- colSums(imported[7:38])
totals1 <- data.frame(added)
totals2 <- t(totals1)
barplot(totals2, cex.names = 0.5, las = 2, main = "Frequency of Minerals")
```
```{r}
#totals2
```


Here is how the top  three minerals compare to all the others added up. Total occurence of minerals.

```{r}
totalObsMined <- sum(totals1)
totalObsMined
```
Mineral occurences when I remove gold, silver, and lead.
```{r}
other <- totalObsMined - totals2[1] - totals2[2] - totals2[3]
other
```

It's easier to visualize as a pie chart.
```{r}
portions <- c(other, totals2[1], totals2[2], totals2[3])
mineObs <- c("other", "Gold", "Silver", "Lead")
pie(portions, labels = mineObs, main = "Occurences of minerals in all the mining operations")
```
I want to see if anything is correlated to gold. I create a data frame with just the minerals for correlation, visualized in a correlation map
```{r}
corrdf <- imported %>% select(
  7:38
)
corrdfvalues <- cor(corrdf)
corrplot(corrdfvalues, tl.srt = 45, tl.cex = .5)
```



## Analysis    

```{r}
#set.seed(123)
#tabImp <- imported[7:38]
```


### Support Vector Machine 
```{r}
#redFC <- imported[7:39]
#redFC
```

```{r}
#redFC
```


```{r}
set.seed(123)
#redFC2 <- redFC[1:32]
#redFC2
redFC <- imported[7:39]
redFC$MineralType <- as.factor(redFC$MineralType)
#redFC
```

```{r}
divider <- createDataPartition(redFC$MineralType, times = 1, p = 0.7, list = FALSE)
train<-redFC[divider,]
test<-redFC[-divider,]
str(train)
```




```{r}
svmModel <- svm(train$MineralType ~., data = train)
svmModel
```
```{r}
table(train$MineralType)
```
```{r}
outcome <- predict(svmModel, train)
table(Predicted = outcome, Tagged = train$MineralType)
```


```{r}
testOutcome <- predict(svmModel, test)
table(Predicted = testOutcome, Tagged = test$MineralType)
```



### Logistic regression  

```{r}
tabImp <- imported[7:38]
mineralsAuAgPb <- glm(Gold ~ Silver + Lead, data = tabImp) 
summary(mineralsAuAgPb)
```
```{r}
mineralAuAg <- glm(Gold ~ Silver, data = tabImp)
par(mfrow=c(2,2))
plot(mineralsAuAgPb, col = mineralsAuAgPb$Silver)
abline(mineralAuAg, col = "blue")
```
```{r}
mineralAuPb <- glm(Gold ~ Lead, data = imported)
par(mfrow=c(2,2))
plot(mineralAuPb, col=mineralAuAg$L)
abline(mineralAuPb, col = "blue")
```

```{r}
anova(mineralsAuAgPb)
```


```{r}
par(mfrow=c(2,2))
plot(mineralsAuAgPb)
```

```{r}
coef(mineralsAuAgPb)
```






## Conclusion  
When I started this project I thought that I was making a pretty good choice for data relating to classification and prediction. It turned out to be more difficult to predict the presence of gold with the provided data set than I had supposed. I thought that the problem was determining the correct classification and prediction algorithms. It turned out that the real problem that needed defining was how to transform the data set. As I started exploring the data I realized that the data was categorical and was really best suited for descriptive statics (number of mines, type of ore extracted, mine location, etc.). In order to use the data, I would have to transform it into quantitative discrete data. I did this through manual one-hot encoding, creating individual variables for each mineral mined and recording a 1 for mineral present, a zero for not present. The data collection was relatively easy as I was able to download it from one site and the individual data sets had pretty much the same structure. The data difficulty level was also not too bad with simple row binding of the sets and some mess to the data. One of the columns was inconsistent with similar columns requiring it to be converted to factor. Data cleaning was moderate with removal of NAs from a lot of the columns. Data inspection (initial analysis/EDA) effort was also moderate revealing that transformations were necessary before real descriptive statistics or inferential statistics could be applied. Feature selection was a continuous process throughout the project to try to reduce the number of original variables. At times, I had to go back and revise the variable selection. Once I selected the variables, I had to engineer features (one hot encoding) from categorical to quantitative discrete. The project was coded in R but the feature engineering was done manually in LibreOffice Calc. I used multiple R libraries for the project. The machine learning methods I used for this project were SVM and logistic regression. I guess one could consider my use of a correlation map as giving some business insight into prospecting for gold. SVM results in low p values. I reject the null hypothesis so the group differences are significant. Because the model statistic is high I can rely on the model. This suggests that the presence of silver is a predictor of gold while the presence of lead predicts the absence of gold. I do not feel real confident about the answers that I got. I think that the SVM model is flexible enough that the results using quantitative discrete data are acceptable for silver and lead.The basic reasoning for my prediction goes like this, the groups are different, I prove it by running svm and it can create a hyperplane classifying the groups. Since the group differences are not due to chance, I can run logistic modeling to predict the occurrence of gold.



