---
title: "Regis University, Master of Science in Data Science, Practicum II - Predicting Gold Presence"
author: "Matt Twigg"
date: "8/22/2020"
output: html_document
---

```{r setup, message=FALSE , warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction  

I used to live in the Black Hills and would go gold panning. Unfortunately, I never found any gold even though I had heard that only half of the gold in the Black Hills had been extracted. Also, gold panning can be tiring as one sits or stands in the same position for a while.  It occurs to me that if I use data science techniques, I might be able to predict where to find gold. If gold shows up with certain other minerals, I can narrow down the areas that I pan for gold. I will create a train/test split to test for accuracy and use support vector machine for classification and prediction of gold.

My specific research question is “Can the presence of gold be predicted from the presence of other minerals?” 

The USGS is a great resource for understanding where minerals were found and what minerals were present. I plan to use data sets from https://mrdata.usgs.gov/mrds/geo-inventory.php for Lawrence County, South Dakota to predict whether gold can be found in the area of other minerals. These data sets give latitude, longitude, and mineral data for given locations. The data sets have missing values, characters, and multiple pieces of information in single fields. The data will have to be cleaned and prepped in order to be useful. Multiple data sets will have to be combined into one data frame. Multiple rows will have to be dropped and only some fields selected. I will be using Rstudio to work with the data sets and storing the rmarkdown on GitHub. 

I am starting off with the following null and alternative hypothesis for the independent variables gold, silver, and lead (I looked at the two most prevalent minerals after gold. In order for the presence of silver or lead to predict the presence of gold, difference between the groups can not be due to chance.

Null hypthesis: any differences in the groups are due to chance - they are not significant. 
Alternative hypothesis: differences are not due to chance - they are significant
 

### Libraries used  
```{r message=FALSE ,warning=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
library(corrplot)
library(factoextra)
library(e1071)
library(caret)
library(class)
library(gmodels)
```

## Exploration  
Data read in from https://mrdata.usgs.gov/mrds/geo-inventory.php for Lawrence County, South Dakota.
```{r message=FALSE ,warning=FALSE}
dn <- read.csv("deadwoodnorth.csv")
ds <- read.csv("deadwoodsouth.csv")
ld <- read.csv("lead.csv")
tn <- read_csv("tinton.csv")
sp <- read_csv("spearfish.csv")
```
Here I bind all the data frames into one data frame.  
```{r}
sites <- rbind(dn, ds, ld, tn, sp)
```
I select only the fields that I will need from the sites data frame.
```{r}
s1 <- sites %>% select(
  dep_id,
  site_name,
  latitude,
  longitude,
  commod1,
  commod2,
  commod3,
)
```
I copy the data frame to s2.
```{r}
s2 <- data.frame(s1)
```
I have to change one of the columns to factor to make it match the other two commod columns.
```{r}
s2$commod2 <- as.factor(s2$commod2)
```
Here is the structure of the new data frame.
```{r}
str(s2)
```
I unite commod1, 2, and 3 into one column called commodities.
```{r}
s2com <- unite(s2, commodities, 5:7, sep = ", ")
#str(s2com)
```
I create a vector with TRUE or FALSE for the presence of gold in each row of the data frame.
```{r}
au <- str_detect(s2com$commodities, "Gold")
```
I add that column to the data frame.
```{r}
s2com1 <- cbind(s2com, au)
```
I reassemble the data frame with all gold mining in the first 299 rows of the data frame.
```{r}
reds2com <- subset(s2com1, au == TRUE)
reds2comF <- subset(s2com1, au == FALSE)
reds <- rbind(reds2com, reds2comF)
```
I give the rows numbers for easy reference.  
```{r}
rownames(reds) <- 1:nrow(reds)
```
I separate out each mineral into its own column.
```{r}
colreds <- reds %>% separate(commodities, c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", "seventeen", "eighteen"), "," ) 
```
I need to know which columns are empty so I count the NA values. 
```{r}
colSums(is.na(colreds))
```
and any columns that have 403 NAs get cut.  
```{r}
reducedcol <- colreds %>% select(1:15)
```
I replace NA with no spaces, create a new data frame, make sure there are no more NA values, and unite all the expanded columns into one commodities column for easy reading of minerals. I then write the file out to be worked on manually, the final step in turning categorical data into quantitative discrete data.
```{r}
noNA <- reducedcol %>% replace_na(list(four = "", five = "", six  = "", seven  = "", eight  = "", nine = "", ten  = "", eleven  = ""))
noNA[noNA == " NA"] <- ""
outFull <- unite(noNA, commodities, 5:15, sep = ", ")
#write.csv(outFull, file = "outFull2.csv")
```
Here I read in the new data set with each mineral having its own column.
```{r}
imported <- read.csv("inFull2.csv")
```
I need to see the structure of the new data set. Here I see that the mineral variables are numerical and discrete.
```{r}
str(imported)
```
I also want to write out the lat/long data for gold mines. I will use this later in Google Earth Pro.
```{r}
allLatLong <- imported[3:5]
latLong <- allLatLong[1:299,]
write.csv(latLong, file = "latLong.csv")
```



## Exploratory Data Analysis

I start off by creating a data frame with the mineral variables to run correlations on.
```{r}
corrdf <- imported %>% select(
  7:38
)
```
I run the correlations using the spearman method since the data is non-parametric. I only want to see the first 3 correlation to gold (gold, silver, lead). 
```{r}
allcor <- cor(corrdf, method = "spearman")
head(allcor[1:3])
```

I want to see  the sums of each mineral. It looks like Gold, Silver, and Lead had the most observations.
```{r}

colMinerals <- names(imported)
added <- colSums(imported[7:38])
totals1 <- data.frame(added)
totals2 <- t(totals1)
totals2
```
Total occurrence of minerals.  
```{r}
totalObsMined <- sum(totals1)
totalObsMined
```

## Visualizations 
Here is the count visualized.
```{r}
barplot(totals2, cex.names = 0.5, las = 2, main = "Frequency of Minerals")
```


Mineral occurrences when I remove gold, silver, and lead.  
```{r}
other <- totalObsMined - totals2[1] - totals2[2] - totals2[3]
other
```

It's easier to visualize as a pie chart.
```{r}
portions <- c(other, totals2[1], totals2[2], totals2[3])
mineObs <- c("other", "Gold", "Silver", "Lead")
pie(portions, labels = mineObs, main = "Occurences of minerals in all the mining operations")
```
I want to see if anything is correlated to gold. I create a data frame with just the minerals for correlation, visualized in a correlation map. Up in the left corner are the correlations of gold, silver, and lead to each other.
```{r}
##corrdf <- imported %>% select(
##  7:38
##)
corrdfvalues <- cor(corrdf)
corrplot(corrdfvalues, tl.srt = 45, tl.cex = .5)
```

## Analysis    

### Support Vector Machine 
I need to create a data set that has the quantitative value along with the binary factor of gold present or not. I leave gold out I am looking to see if all the dependent variables will lead to correct classification of the target mineral (gold) is present.  
```{r}
set.seed(123)
tempMin <- imported[8:38]
tempTarget <- imported[40]
tempReducedWithFactorCombined <-as.data.frame(c(tempMin,tempTarget))
redFC <- tempReducedWithFactorCombined
head(redFC)
```

I create test and train data sets.  
```{r}
set.seed(123)
divider <- createDataPartition(redFC$targetMineral, times = 1, p = 0.7, list = FALSE)
train<-redFC[divider,]
test<-redFC[-divider,]
```

I generate the svm model using the train data set. As the data is not linear svm knows to use a radial kernal. 
```{r message=FALSE ,warning=FALSE}
svmModel <- svm(train$targetMineral ~., data = train)
svmModel
```

using the test data set the svm model generated a confusion matrix of (4+88)/(4+88+1+27) = 92/120 = 76.7% accuracy.  
```{r}
testOutcome <- predict(svmModel, test)
table(Predicted = testOutcome, Tagged = test$targetMineral)
```

### Logistic Regression
I got guidance from https://www.guru99.com/r-generalized-linear-model.html and modified some to the code for my needs.  

I use logistic regression to predict gold from presence of silver. I choose silver because it has the higher correlation and is a positive correlation to gold. I also use logistic regression to examine the p-value of silver. I choose the binomial family because the dependent variable is binary. 
```{r}
mineralsAuAg <- glm(train$targetMineral ~ Silver, data = train, family = "binomial") 
summary(mineralsAuAg)
```
I do the same for silver
```{r}
mineralsAuPb <- glm(train$targetMineral ~ Lead, data = train, family = "binomial") 
summary(mineralsAuPb)
```
At this point I am really not sure about the results because the results are not standard. I simply could not find an answer to the question of how (or is it possible) to run logistic regression on my data set. Intuitively, it seems like it would work as the independent variables are numerical and the dependent variable is binary. P-value is very low so I can reject the null hypothesis, the difference between gold and lead is not due to chance.
```{r}
mineralsAuAg <- glm(train$targetMineral ~ Silver, data = train, family = "binomial") 
summary(mineralsAuAg)
```
I do the same for lead. P-value is very low so I can reject the null hypothesis, the difference between gold and lead is not due to chance.
```{r}
mineralsAuPb <- glm(train$targetMineral ~ Lead, data = train, family = "binomial") 
summary(mineralsAuPb)
``` 

I run the logistic regression model on the test data set and round the data giving only 0 and 2. I interpret 0 as no and 2 as yes for predicting gold.
```{r}
predictGold <- predict(mineralsAuAg, test)
predictGold <- round(predictGold)
predictGold
```
I run a confusion matrix for silver predicting gold. It is really out of standard results now. Again, I interpret 0 as no and 2 as yes.  
It looks like the accuracy is (19 + 74)/(19+74+12+15) = 93/120 = .775 = 77.5%. 
```{r}
confusionM <- table(test$targetMineral, predictGold)
confusionM
```

## Conclusion  
When I started this project I thought that I was making a pretty good choice for data relating to classification and prediction. It turned out to be more difficult to predict the presence of gold with the provided data set than I had supposed.  

I thought that the problem was determining the correct classification and prediction algorithms. It turned out that the real problem that needed defining was how to transform the data set. As I started exploring the data I realized that the data was categorical and was really best suited for descriptive statics (number of mines, type of ore extracted, mine location, etc.). In order to use the data, I would have to transform it into quantitative discrete data. I did this through manual one-hot encoding, creating individual variables for each mineral mined and recording a 1 for mineral present, a zero for not present. The data collection was relatively easy as I was able to download it from one site and the individual data sets had pretty much the same structure. The data difficulty level was also not too bad with simple row binding of the sets and some mess to the data. One of the columns was inconsistent with similar columns requiring it to be converted to factor. Data cleaning was moderate with removal of NAs from a lot of the columns. Data inspection (initial analysis/EDA) effort was also moderate revealing that transformations were necessary before real descriptive statistics or inferential statistics could be applied. Feature selection was a continuous process throughout the project to try to reduce the number of original variables. At times, I had to go back and revise the variable selection. Once I selected the variables, I had to engineer features (one hot encoding) from categorical to quantitative discrete. The project was coded in R but the feature engineering was done manually in LibreOffice Calc by writing out files and importing the manually created file with new features. I used multiple R libraries for the project. The machine learning methods I used for this project were SVM and logistic regression and I may have taken liberties that are not allowed for a data set such as I created.   

I guess one could consider my use of a correlation map as giving some business insight into prospecting for gold. The logistic modelling resulted in low p values. Thus, I rejected the null hypothesis. The group differences were significant. The logistic model results indicate that the presence of silver is a predictor of gold while the presence of lead predicts the absence of gold. I do not feel real confident about the results that I got. I think that the SVM model is flexible enough that the results using quantitative discrete data are acceptable for silver and lead. SVM classification was 76% accurate. If I have done everything correctly, my prediction project goes like this: the groups are different, I prove it by running svm and it can create a hyperplane classifying the groups. Since the group differences are not due to chance, the logistic model does predict the occurrence of gold. However, this all rests on the premise that I have used the right data set with the right machine learning methods. I at least tried to stick to machine learning methods for non-parametric data.

I do believe that this project did provide some business insight by showing where gold clusters were physically by mapping the mines in Google Earth Pro, by showing correlations between gold and other minerals, and by visualizing the occurence of gold with silver, lead, and other minerals.








